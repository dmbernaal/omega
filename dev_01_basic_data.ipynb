{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R-Regression Dataset\n",
    "In this notebook we will take much of what we have explored via our sandbox notebooks and create a dataset tuned for regression. We will use our stationary close to create our labels which will range from -1 to 1. \n",
    "\n",
    "The models that follow for each task will take in the same data, the only difference being the dataset creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:24:07.515817Z",
     "iopub.status.busy": "2020-10-07T00:24:07.515817Z",
     "iopub.status.idle": "2020-10-07T00:24:08.326647Z",
     "shell.execute_reply": "2020-10-07T00:24:08.326647Z",
     "shell.execute_reply.started": "2020-10-07T00:24:07.515817Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('seaborn')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:24:09.023819Z",
     "iopub.status.busy": "2020-10-07T00:24:09.022823Z",
     "iopub.status.idle": "2020-10-07T00:24:09.028807Z",
     "shell.execute_reply": "2020-10-07T00:24:09.028807Z",
     "shell.execute_reply.started": "2020-10-07T00:24:09.023819Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(root=None, remove=None, headers=None):\n",
    "    data = Path('./OmegaDev/Model_Z/raw_data/GBP_USD_H1_2016-01-01_2018-01-01.csv') if root is None else Path(root)\n",
    "    headers = ['date', 'complete', 'open', 'high', 'low', 'close', 'volume'] if headers is None else headers\n",
    "    df = pd.read_csv(data, header=None, names=headers)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:24:09.183393Z",
     "iopub.status.busy": "2020-10-07T00:24:09.182396Z",
     "iopub.status.idle": "2020-10-07T00:24:09.187382Z",
     "shell.execute_reply": "2020-10-07T00:24:09.187382Z",
     "shell.execute_reply.started": "2020-10-07T00:24:09.183393Z"
    }
   },
   "outputs": [],
   "source": [
    "def stationary_close(df, col='close', diff=1):\n",
    "    \"\"\"\n",
    "    difference in timesteps. By default this will be set to 1 which in this case is 1 hour difference. \n",
    "    \n",
    "    The difference should be the time-window that is used to label data.\n",
    "    \"\"\"\n",
    "    return np.tanh(df[col].diff(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:24:09.330001Z",
     "iopub.status.busy": "2020-10-07T00:24:09.330001Z",
     "iopub.status.idle": "2020-10-07T00:24:09.333991Z",
     "shell.execute_reply": "2020-10-07T00:24:09.333991Z",
     "shell.execute_reply.started": "2020-10-07T00:24:09.330001Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Window will be the timeframe we will be looking at for labeling data. That we will be taking 4 timesteps to label the 5th timestep. \n",
    "\n",
    "This will later be used when stacking our images as each 'image' will represent a WINDOW sequence length\n",
    "\"\"\"\n",
    "WINDOW = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:24:11.374762Z",
     "iopub.status.busy": "2020-10-07T00:24:11.374762Z",
     "iopub.status.idle": "2020-10-07T00:24:11.413656Z",
     "shell.execute_reply": "2020-10-07T00:24:11.413656Z",
     "shell.execute_reply.started": "2020-10-07T00:24:11.374762Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df['close_label'] = df['close']\n",
    "# df['stationary_close'] = stationary_close(df, 'close', WINDOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technicals + Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:24:11.800621Z",
     "iopub.status.busy": "2020-10-07T00:24:11.800621Z",
     "iopub.status.idle": "2020-10-07T00:24:12.354173Z",
     "shell.execute_reply": "2020-10-07T00:24:12.354173Z",
     "shell.execute_reply.started": "2020-10-07T00:24:11.800621Z"
    }
   },
   "outputs": [],
   "source": [
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:24:12.356138Z",
     "iopub.status.busy": "2020-10-07T00:24:12.355168Z",
     "iopub.status.idle": "2020-10-07T00:24:17.937407Z",
     "shell.execute_reply": "2020-10-07T00:24:17.937407Z",
     "shell.execute_reply.started": "2020-10-07T00:24:12.356138Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmber\\Anaconda3\\lib\\site-packages\\ta\\trend.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i]/self._trs[i])\n",
      "C:\\Users\\dmber\\Anaconda3\\lib\\site-packages\\ta\\trend.py:612: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i]/self._trs[i])\n"
     ]
    }
   ],
   "source": [
    "df = add_all_ta_features(df, 'open', 'high', 'low', 'close', 'volume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:24:22.977581Z",
     "iopub.status.busy": "2020-10-07T00:24:22.977581Z",
     "iopub.status.idle": "2020-10-07T00:24:22.982568Z",
     "shell.execute_reply": "2020-10-07T00:24:22.982568Z",
     "shell.execute_reply.started": "2020-10-07T00:24:22.977581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'complete', 'open', 'high', 'low', 'close', 'volume',\n",
       "       'close_label', 'volume_adi', 'volume_obv', 'volume_cmf', 'volume_fi',\n",
       "       'momentum_mfi', 'volume_em', 'volume_sma_em', 'volume_vpt',\n",
       "       'volume_nvi', 'volume_vwap', 'volatility_atr', 'volatility_bbm',\n",
       "       'volatility_bbh', 'volatility_bbl', 'volatility_bbw', 'volatility_bbp',\n",
       "       'volatility_bbhi', 'volatility_bbli', 'volatility_kcc',\n",
       "       'volatility_kch', 'volatility_kcl', 'volatility_kcw', 'volatility_kcp',\n",
       "       'volatility_kchi', 'volatility_kcli', 'volatility_dcl',\n",
       "       'volatility_dch', 'trend_macd', 'trend_macd_signal', 'trend_macd_diff',\n",
       "       'trend_sma_fast', 'trend_sma_slow', 'trend_ema_fast', 'trend_ema_slow',\n",
       "       'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_vortex_ind_pos',\n",
       "       'trend_vortex_ind_neg', 'trend_vortex_ind_diff', 'trend_trix',\n",
       "       'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst',\n",
       "       'trend_kst_sig', 'trend_kst_diff', 'trend_ichimoku_conv',\n",
       "       'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b',\n",
       "       'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_aroon_up',\n",
       "       'trend_aroon_down', 'trend_aroon_ind', 'trend_psar_up',\n",
       "       'trend_psar_down', 'trend_psar_up_indicator',\n",
       "       'trend_psar_down_indicator', 'momentum_rsi', 'momentum_tsi',\n",
       "       'momentum_uo', 'momentum_stoch', 'momentum_stoch_signal', 'momentum_wr',\n",
       "       'momentum_ao', 'momentum_kama', 'momentum_roc', 'others_dr',\n",
       "       'others_dlr', 'others_cr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.068938Z",
     "iopub.status.busy": "2020-10-04T20:17:51.068938Z",
     "iopub.status.idle": "2020-10-04T20:17:51.076918Z",
     "shell.execute_reply": "2020-10-04T20:17:51.076918Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.068938Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale_data(data, y_col=None, non_float_cols=None, scaler=None):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        y_col: dependent var if y_col is in the master dataframe. \n",
    "        non_float_cols: this can be discreete vars that was will not use for GASF or GADF conversion - such as metadata. This data should be seperated\n",
    "        scaler: scaler to use: example: MinMaxScaler(feature_range(n0, n-1)), RobustScaler(), etc\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    cols_to_ignore = [y_col] + non_float_cols if isinstance(non_float_cols, list) else [y_col] + [non_float_cols]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1)) if scaler is None else scaler\n",
    "    cols_to_scale = [c for c in list(data.columns) if c not in cols_to_ignore]\n",
    "    for c in cols_to_scale:\n",
    "        if data.iloc[:][c].dtype!=np.float64: data[c] = data.iloc[:][c].astype('float64')\n",
    "        dd = data.iloc[:][c].values\n",
    "        dd = dd[:, None]\n",
    "        sc = scaler.fit(dd)\n",
    "        data.iloc[:][c] = sc.transform(dd).squeeze(1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.078912Z",
     "iopub.status.busy": "2020-10-04T20:17:51.077914Z",
     "iopub.status.idle": "2020-10-04T20:17:51.102848Z",
     "shell.execute_reply": "2020-10-04T20:17:51.102848Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.078912Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "removing technicals we dont want\n",
    "\"\"\"\n",
    "remove = ['trend_psar_up', 'trend_psar_down']\n",
    "df.drop(columns=remove,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.103845Z",
     "iopub.status.busy": "2020-10-04T20:17:51.103845Z",
     "iopub.status.idle": "2020-10-04T20:17:51.120834Z",
     "shell.execute_reply": "2020-10-04T20:17:51.120834Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.103845Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Dropping na\n",
    "For now we will use this dummy method. However, it would be best to fill in na with some values. \n",
    "\"\"\"\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.121796Z",
     "iopub.status.busy": "2020-10-04T20:17:51.121796Z",
     "iopub.status.idle": "2020-10-04T20:17:51.201624Z",
     "shell.execute_reply": "2020-10-04T20:17:51.201624Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.121796Z"
    }
   },
   "outputs": [],
   "source": [
    "# grabbing all data\n",
    "data = df.iloc[:,2:].copy()\n",
    "data_dd = scale_data(data, y_col='close_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.202581Z",
     "iopub.status.busy": "2020-10-04T20:17:51.202581Z",
     "iopub.status.idle": "2020-10-04T20:17:51.208565Z",
     "shell.execute_reply": "2020-10-04T20:17:51.208565Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.202581Z"
    }
   },
   "outputs": [],
   "source": [
    "def vol_label(start_idx, df, y_col, window=4, sl_pips=20, tp_pips=40):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    -----------------\n",
    "        stard_idx: <int> the start index should be the last idx of the time-sequence we are using as predicted features (independent vars).\n",
    "                   if our time-series is from [0,1,2,3,4] then our start_idx should be 5 so our prediction label will be: [5, ... ,window]\n",
    "                   therefore, the start_idx should be be the last_idx of our time-series window\n",
    "        \n",
    "        df:        <df> dataframe for predicting\n",
    "        \n",
    "        sl_pips & tp_pips: stop loss pips and take profit pips\n",
    "    \"\"\"\n",
    "    tf = df.iloc[start_idx:start_idx+window][y_col]\n",
    "    price_n = tf.iloc[0]\n",
    "    upper_bound = price_n + (0.0001 * tp_pips)\n",
    "    lower_bound = price_n - (0.0001 * sl_pips)\n",
    "    lbls = []\n",
    "    for c in tf.values:\n",
    "        if c >= upper_bound: lbls.append(1)\n",
    "        elif c <= lower_bound: lbls.append(2)\n",
    "    return lbls[0] if len(lbls) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.210561Z",
     "iopub.status.busy": "2020-10-04T20:17:51.210561Z",
     "iopub.status.idle": "2020-10-04T20:17:51.219536Z",
     "shell.execute_reply": "2020-10-04T20:17:51.219536Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.210561Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data_x(data_dd, y_col=None, cols_to_ignore=None, window_size=24, lbl_window=4, sl_pips=20, tp_pips=40):\n",
    "    \"\"\"\n",
    "    given data_dd (scaled data from some manner), we will return a dictionary of each feature in sequence format. By default the window will be 24 which represents 24 time steps -> in this case a single day of data. \n",
    "    \n",
    "    returns: \n",
    "        ddd: <dict> representing each feature with sequences of data. [0] will contain [n0, nM] where M is the timestep size or 'window_size'. [1] will be [[0]n0+1, [0]nM+1]. therefore, each idx in the array will be a single timestep ahead of the previous one. \n",
    "    \"\"\"\n",
    "    c2i = [y_col] + [cols_to_ignore] if not isinstance(cols_to_ignore, list) else cols_to_ignore\n",
    "    cols2ddd = [c for c in list(data_dd.columns) if c not in c2i]\n",
    "    ddd = {c:[] for c in cols2ddd}\n",
    "    ddd['y'] = []\n",
    "\n",
    "    n = len(data_dd)\n",
    "\n",
    "    start_idx=0\n",
    "    end_idx=window_size\n",
    "    last_idx=n-window_size\n",
    "\n",
    "    while start_idx<last_idx:\n",
    "        # grab features for time-series features\n",
    "        for c in cols2ddd:\n",
    "            sample = data_dd[c]\n",
    "            win = sample.iloc[start_idx:end_idx].values\n",
    "            ddd[c].append(win)\n",
    "        \n",
    "        # grab labels -> preceding window followed by window_size\n",
    "        y = vol_label(end_idx, data_dd, y_col, window=lbl_window, sl_pips=sl_pips, tp_pips=tp_pips)\n",
    "        ddd['y'].append(y)\n",
    "        \n",
    "        # increment\n",
    "        start_idx+=1\n",
    "        end_idx+=1\n",
    "        \n",
    "    return ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.221530Z",
     "iopub.status.busy": "2020-10-04T20:17:51.220533Z",
     "iopub.status.idle": "2020-10-04T20:17:51.228512Z",
     "shell.execute_reply": "2020-10-04T20:17:51.228512Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.221530Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(data_dd, y_col, window_size, lbl_window, sl_pips, tp_pips):\n",
    "    \"\"\"\n",
    "    wrappes around split_x, split_y and returns dictionary with windowed values along with y_values associated with each sequence\n",
    "    \"\"\"\n",
    "    ddd = split_data_x(data_dd, y_col=y_col, window_size=window_size, lbl_window=lbl_window, sl_pips=sl_pips, tp_pips=tp_pips)\n",
    "    return ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.229509Z",
     "iopub.status.busy": "2020-10-04T20:17:51.229509Z",
     "iopub.status.idle": "2020-10-04T20:17:51.236490Z",
     "shell.execute_reply": "2020-10-04T20:17:51.236490Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.229509Z"
    }
   },
   "outputs": [],
   "source": [
    "# def split_data_x(data_dd, y_col=None, cols_to_ignore=None, window_size=24):\n",
    "#     \"\"\"\n",
    "#     given data_dd (scaled data from some manner), we will return a dictionary of each feature in sequence format. By default the window will be 24 which represents 24 time steps -> in this case a single day of data. \n",
    "    \n",
    "#     returns: \n",
    "#         ddd: <dict> representing each feature with sequences of data. [0] will contain [n0, nM] where M is the timestep size or 'window_size'. [1] will be [[0]n0+1, [0]nM+1]. therefore, each idx in the array will be a single timestep ahead of the previous one. \n",
    "#     \"\"\"\n",
    "#     c2i = [y_col] + [cols_to_ignore] if not isinstance(cols_to_ignore, list) else cols_to_ignore\n",
    "#     cols2ddd = [c for c in list(data.columns) if c not in c2i]\n",
    "#     ddd = {c:[] for c in cols2ddd}\n",
    "\n",
    "#     n = len(data_dd)\n",
    "\n",
    "#     start_idx=0\n",
    "#     end_idx=window_size\n",
    "#     last_idx=n-window_size\n",
    "\n",
    "#     while start_idx<last_idx:\n",
    "#         for c in cols2ddd:\n",
    "#             sample = data_dd[c]\n",
    "#             win = sample.iloc[start_idx:end_idx].values\n",
    "#             ddd[c].append(win)\n",
    "#         start_idx+=1\n",
    "#         end_idx+=1\n",
    "        \n",
    "#     return ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.237487Z",
     "iopub.status.busy": "2020-10-04T20:17:51.237487Z",
     "iopub.status.idle": "2020-10-04T20:17:51.241479Z",
     "shell.execute_reply": "2020-10-04T20:17:51.241479Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.237487Z"
    }
   },
   "outputs": [],
   "source": [
    "# def split_data_y(data_dd, y_col, window_size=4):\n",
    "#     \"\"\"\n",
    "#     This is the same as the other split func. However, this should return the Y values depending on the window size. The window size should be the same\n",
    "#     \"\"\"\n",
    "#     n = len(data_dd)\n",
    "#     start_idx=0\n",
    "#     end_idx=window_size\n",
    "#     last_idx=n-window_size\n",
    "#     y_values = []\n",
    "    \n",
    "#     while start_idx<last_idx:\n",
    "#         y = data_dd.iloc[end_idx][y_col]\n",
    "#         y_values.append(y)\n",
    "#         start_idx+=1\n",
    "#         end_idx+=1\n",
    "        \n",
    "#     return y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.242474Z",
     "iopub.status.busy": "2020-10-04T20:17:51.242474Z",
     "iopub.status.idle": "2020-10-04T20:17:51.246489Z",
     "shell.execute_reply": "2020-10-04T20:17:51.246489Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.242474Z"
    }
   },
   "outputs": [],
   "source": [
    "# def split_data(data_dd, y_col, window_size):\n",
    "#     \"\"\"\n",
    "#     wrappes around split_x, split_y and returns dictionary with windowed values along with y_values associated with each sequence\n",
    "#     \"\"\"\n",
    "#     ddd = split_data_x(data_dd, y_col=y_col, window_size=window_size)\n",
    "#     y = split_data_y(data_dd, y_col=y_col, window_size=window_size)\n",
    "#     ddd['y'] = y\n",
    "#     return ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T20:17:51.247461Z",
     "iopub.status.busy": "2020-10-04T20:17:51.247461Z",
     "iopub.status.idle": "2020-10-04T20:19:00.202124Z",
     "shell.execute_reply": "2020-10-04T20:19:00.202124Z",
     "shell.execute_reply.started": "2020-10-04T20:17:51.247461Z"
    }
   },
   "outputs": [],
   "source": [
    "### grabbing timesteps in dictionary format\n",
    "lbl_window=4\n",
    "ddd = split_data(data_dd, y_col='close_label', window_size=WINDOW, lbl_window=lbl_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:27:13.522935Z",
     "iopub.status.busy": "2020-10-05T00:27:13.522935Z",
     "iopub.status.idle": "2020-10-05T00:27:13.526924Z",
     "shell.execute_reply": "2020-10-05T00:27:13.526924Z",
     "shell.execute_reply.started": "2020-10-05T00:27:13.522935Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:28:28.204707Z",
     "iopub.status.busy": "2020-10-05T00:28:28.203710Z",
     "iopub.status.idle": "2020-10-05T00:28:28.212248Z",
     "shell.execute_reply": "2020-10-05T00:28:28.211689Z",
     "shell.execute_reply.started": "2020-10-05T00:28:28.204707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 4237, -1: 4058, 1: 4038})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(np.array(ddd['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:29:52.601238Z",
     "iopub.status.busy": "2020-10-05T00:29:52.600239Z",
     "iopub.status.idle": "2020-10-05T00:29:52.606224Z",
     "shell.execute_reply": "2020-10-05T00:29:52.605226Z",
     "shell.execute_reply.started": "2020-10-05T00:29:52.601238Z"
    }
   },
   "outputs": [],
   "source": [
    "def stack(ddd):\n",
    "    \"\"\"\n",
    "    Stacking our dictionary from our split into the appropriate shape. This is necessary for GAXF formation and for data iteration when passing through the dataset class\n",
    "    \n",
    "    shape:\n",
    "    ----------\n",
    "    [n, n_features]\n",
    "        n: number of samples, in this case this should be the length of the master dataframe after dropna (if applied)\n",
    "        n_features: in this case is the sequence size. Or the 'window_size' as it represents a sequence of f type features -> a feature being close, open, etc\n",
    "    \"\"\"\n",
    "    ddd = {k:np.stack(v) for k,v in ddd.items()}\n",
    "    ddd['y'] = ddd['y'][:,None]\n",
    "    return ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:29:52.835683Z",
     "iopub.status.busy": "2020-10-05T00:29:52.835683Z",
     "iopub.status.idle": "2020-10-05T00:29:54.186773Z",
     "shell.execute_reply": "2020-10-05T00:29:54.186773Z",
     "shell.execute_reply.started": "2020-10-05T00:29:52.835683Z"
    }
   },
   "outputs": [],
   "source": [
    "# stacking our features along with our y\n",
    "ddd = stack(ddd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAXF Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:30:02.007639Z",
     "iopub.status.busy": "2020-10-05T00:30:02.007639Z",
     "iopub.status.idle": "2020-10-05T00:30:03.541648Z",
     "shell.execute_reply": "2020-10-05T00:30:03.541648Z",
     "shell.execute_reply.started": "2020-10-05T00:30:02.007639Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyts.image import GramianAngularField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:30:03.542642Z",
     "iopub.status.busy": "2020-10-05T00:30:03.542642Z",
     "iopub.status.idle": "2020-10-05T00:30:03.546622Z",
     "shell.execute_reply": "2020-10-05T00:30:03.546622Z",
     "shell.execute_reply.started": "2020-10-05T00:30:03.542642Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_gasfd_defaults(size=None):\n",
    "    size = 24 if size is None else size\n",
    "    assert isinstance(size, int), 'size should be an int'\n",
    "    gasf = GramianAngularField(image_size=size, method='summation')\n",
    "    gadf = GramianAngularField(image_size=size, method='difference')\n",
    "    return gasf, gadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:30:03.547596Z",
     "iopub.status.busy": "2020-10-05T00:30:03.547596Z",
     "iopub.status.idle": "2020-10-05T00:30:03.563091Z",
     "shell.execute_reply": "2020-10-05T00:30:03.562094Z",
     "shell.execute_reply.started": "2020-10-05T00:30:03.547596Z"
    }
   },
   "outputs": [],
   "source": [
    "def gaxf_convert(ddd, c2='gasf', size=None):\n",
    "    \"\"\"\n",
    "    GAXF, where x is either S or D. \n",
    "\n",
    "    We will now convert our windowed data and convert each into a GAXf format. This is what will be fed into the PyTorch model STACKED for the number of features we want to use as independent vars.\n",
    "    \"\"\"\n",
    "    if c2.lower() not in ['gasf', 'gadf']: return\n",
    "    gasf, gadf = create_gasfd_defaults(size=size)\n",
    "    if c2=='gasf': temp = {k:gasf.fit_transform(v) for k,v in ddd.items() if k!='y'}\n",
    "    else: temp =  {k:gadf.fit_transform(v) for k,v in ddd.items() if k!='y'}\n",
    "    temp['y'] = ddd['y']\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:30:03.565086Z",
     "iopub.status.busy": "2020-10-05T00:30:03.565086Z",
     "iopub.status.idle": "2020-10-05T00:30:10.228209Z",
     "shell.execute_reply": "2020-10-05T00:30:10.228209Z",
     "shell.execute_reply.started": "2020-10-05T00:30:03.565086Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating GASF from our timesteps. The image size will be the window size.\n",
    "\"\"\"\n",
    "ddd_GASF = gaxf_convert(ddd, c2='gasf', size=WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:30:10.229188Z",
     "iopub.status.busy": "2020-10-05T00:30:10.229188Z",
     "iopub.status.idle": "2020-10-05T00:30:10.233148Z",
     "shell.execute_reply": "2020-10-05T00:30:10.233148Z",
     "shell.execute_reply.started": "2020-10-05T00:30:10.229188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12333, 24, 24)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd_GASF['open'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-05T00:30:10.235143Z",
     "iopub.status.busy": "2020-10-05T00:30:10.234147Z",
     "iopub.status.idle": "2020-10-05T00:30:10.253126Z",
     "shell.execute_reply": "2020-10-05T00:30:10.252122Z",
     "shell.execute_reply.started": "2020-10-05T00:30:10.235143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open (12333, 24, 24)\n",
      "high (12333, 24, 24)\n",
      "low (12333, 24, 24)\n",
      "close (12333, 24, 24)\n",
      "volume (12333, 24, 24)\n",
      "volume_adi (12333, 24, 24)\n",
      "volume_obv (12333, 24, 24)\n",
      "volume_cmf (12333, 24, 24)\n",
      "volume_fi (12333, 24, 24)\n",
      "momentum_mfi (12333, 24, 24)\n",
      "volume_em (12333, 24, 24)\n",
      "volume_sma_em (12333, 24, 24)\n",
      "volume_vpt (12333, 24, 24)\n",
      "volume_nvi (12333, 24, 24)\n",
      "volume_vwap (12333, 24, 24)\n",
      "volatility_atr (12333, 24, 24)\n",
      "volatility_bbm (12333, 24, 24)\n",
      "volatility_bbh (12333, 24, 24)\n",
      "volatility_bbl (12333, 24, 24)\n",
      "volatility_bbw (12333, 24, 24)\n",
      "volatility_bbp (12333, 24, 24)\n",
      "volatility_bbhi (12333, 24, 24)\n",
      "volatility_bbli (12333, 24, 24)\n",
      "volatility_kcc (12333, 24, 24)\n",
      "volatility_kch (12333, 24, 24)\n",
      "volatility_kcl (12333, 24, 24)\n",
      "volatility_kcw (12333, 24, 24)\n",
      "volatility_kcp (12333, 24, 24)\n",
      "volatility_kchi (12333, 24, 24)\n",
      "volatility_kcli (12333, 24, 24)\n",
      "volatility_dcl (12333, 24, 24)\n",
      "volatility_dch (12333, 24, 24)\n",
      "trend_macd (12333, 24, 24)\n",
      "trend_macd_signal (12333, 24, 24)\n",
      "trend_macd_diff (12333, 24, 24)\n",
      "trend_sma_fast (12333, 24, 24)\n",
      "trend_sma_slow (12333, 24, 24)\n",
      "trend_ema_fast (12333, 24, 24)\n",
      "trend_ema_slow (12333, 24, 24)\n",
      "trend_adx (12333, 24, 24)\n",
      "trend_adx_pos (12333, 24, 24)\n",
      "trend_adx_neg (12333, 24, 24)\n",
      "trend_vortex_ind_pos (12333, 24, 24)\n",
      "trend_vortex_ind_neg (12333, 24, 24)\n",
      "trend_vortex_ind_diff (12333, 24, 24)\n",
      "trend_trix (12333, 24, 24)\n",
      "trend_mass_index (12333, 24, 24)\n",
      "trend_cci (12333, 24, 24)\n",
      "trend_dpo (12333, 24, 24)\n",
      "trend_kst (12333, 24, 24)\n",
      "trend_kst_sig (12333, 24, 24)\n",
      "trend_kst_diff (12333, 24, 24)\n",
      "trend_ichimoku_conv (12333, 24, 24)\n",
      "trend_ichimoku_base (12333, 24, 24)\n",
      "trend_ichimoku_a (12333, 24, 24)\n",
      "trend_ichimoku_b (12333, 24, 24)\n",
      "trend_visual_ichimoku_a (12333, 24, 24)\n",
      "trend_visual_ichimoku_b (12333, 24, 24)\n",
      "trend_aroon_up (12333, 24, 24)\n",
      "trend_aroon_down (12333, 24, 24)\n",
      "trend_aroon_ind (12333, 24, 24)\n",
      "trend_psar_up_indicator (12333, 24, 24)\n",
      "trend_psar_down_indicator (12333, 24, 24)\n",
      "momentum_rsi (12333, 24, 24)\n",
      "momentum_tsi (12333, 24, 24)\n",
      "momentum_uo (12333, 24, 24)\n",
      "momentum_stoch (12333, 24, 24)\n",
      "momentum_stoch_signal (12333, 24, 24)\n",
      "momentum_wr (12333, 24, 24)\n",
      "momentum_ao (12333, 24, 24)\n",
      "momentum_kama (12333, 24, 24)\n",
      "momentum_roc (12333, 24, 24)\n",
      "others_dr (12333, 24, 24)\n",
      "others_dlr (12333, 24, 24)\n",
      "others_cr (12333, 24, 24)\n",
      "y (12333, 1)\n"
     ]
    }
   ],
   "source": [
    "for k in ddd_GASF.keys():\n",
    "    print(k, ddd_GASF[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
