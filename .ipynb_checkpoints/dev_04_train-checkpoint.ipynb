{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading other modules -> used to create train module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T20:05:30.090714Z",
     "iopub.status.busy": "2020-10-17T20:05:30.090714Z",
     "iopub.status.idle": "2020-10-17T20:05:32.420695Z",
     "shell.execute_reply": "2020-10-17T20:05:32.420695Z",
     "shell.execute_reply.started": "2020-10-17T20:05:30.090714Z"
    }
   },
   "outputs": [],
   "source": [
    "from nb.models import mininest_ba, mininest_bn, mininet, xmininet, xsemininet\n",
    "from nb.databunch import DataBunch\n",
    "from nb.learner import Learner, model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T20:05:36.806493Z",
     "iopub.status.busy": "2020-10-17T20:05:36.805465Z",
     "iopub.status.idle": "2020-10-17T20:05:36.809486Z",
     "shell.execute_reply": "2020-10-17T20:05:36.809486Z",
     "shell.execute_reply.started": "2020-10-17T20:05:36.806493Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm as tq\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T20:05:37.049814Z",
     "iopub.status.busy": "2020-10-17T20:05:37.049814Z",
     "iopub.status.idle": "2020-10-17T20:05:37.052774Z",
     "shell.execute_reply": "2020-10-17T20:05:37.052774Z",
     "shell.execute_reply.started": "2020-10-17T20:05:37.049814Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T20:05:37.740931Z",
     "iopub.status.busy": "2020-10-17T20:05:37.740931Z",
     "iopub.status.idle": "2020-10-17T20:05:37.744939Z",
     "shell.execute_reply": "2020-10-17T20:05:37.744939Z",
     "shell.execute_reply.started": "2020-10-17T20:05:37.740931Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-17T20:05:38.033165Z",
     "iopub.status.busy": "2020-10-17T20:05:38.033165Z",
     "iopub.status.idle": "2020-10-17T20:06:11.109803Z",
     "shell.execute_reply": "2020-10-17T20:06:11.109803Z",
     "shell.execute_reply.started": "2020-10-17T20:05:38.033165Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dmber\\Anaconda3\\lib\\site-packages\\ta\\trend.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i]/self._trs[i])\n",
      "C:\\Users\\dmber\\Anaconda3\\lib\\site-packages\\ta\\trend.py:612: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i]/self._trs[i])\n",
      "C:\\Users\\dmber\\Anaconda3\\lib\\site-packages\\ta\\trend.py:608: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dip[i] = 100 * (self._dip[i]/self._trs[i])\n",
      "C:\\Users\\dmber\\Anaconda3\\lib\\site-packages\\ta\\trend.py:612: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  din[i] = 100 * (self._din[i]/self._trs[i])\n"
     ]
    }
   ],
   "source": [
    "def load_data(root=None, remove=None, headers=None):\n",
    "    data = Path('./OmegaDev/Model_Z/raw_data/GBP_USD_H1_2015-01-01_2020-01-01.csv') if root is None else Path(root)\n",
    "    headers = ['date', 'complete', 'open', 'high', 'low', 'close', 'volume'] if headers is None else headers\n",
    "    df = pd.read_csv(data, header=None, names=headers)\n",
    "    return df\n",
    "\n",
    "# loading our dataframe\n",
    "df = load_data()\n",
    "\n",
    "# TAs to remove -> memory constraint\n",
    "ta_to_remove = ['others_dr', 'others_dlr', 'others_cr', 'momentum_rsi', 'momentum_tsi', 'momentum_uo', 'momentum_stoch', 'momentum_stoch_signal', 'momentum_wr', 'momentum_ao', 'momentum_kama', 'momentum_roc', 'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_psar_up_indicator', 'trend_psar_down_indicator', 'trend_aroon_down', 'trend_aroon_ind', 'trend_aroon_up']\n",
    "\n",
    "ta_to_remove = ['volume_adi', 'volume_obv', 'volume_cmf', 'volume_fi',\n",
    "       'momentum_mfi', 'volume_em', 'volume_sma_em', 'volume_vpt',\n",
    "       'volume_nvi', 'volume_vwap', 'volatility_atr', 'volatility_bbm',\n",
    "       'volatility_bbh', 'volatility_bbl', 'volatility_bbw', 'volatility_bbp',\n",
    "       'volatility_bbhi', 'volatility_bbli', 'volatility_kcc',\n",
    "       'volatility_kch', 'volatility_kcl', 'volatility_kcw', 'volatility_kcp',\n",
    "       'volatility_kchi', 'volatility_kcli', 'volatility_dcl',\n",
    "       'volatility_dch', 'trend_macd', 'trend_macd_signal', 'trend_macd_diff',\n",
    "       'trend_sma_fast', 'trend_sma_slow', 'trend_ema_fast', 'trend_ema_slow',\n",
    "       'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_vortex_ind_pos',\n",
    "       'trend_vortex_ind_neg', 'trend_vortex_ind_diff', 'trend_trix',\n",
    "       'trend_mass_index', 'trend_cci', 'trend_dpo', 'trend_kst',\n",
    "       'trend_kst_sig', 'trend_kst_diff', 'trend_ichimoku_conv',\n",
    "       'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b',\n",
    "       'trend_visual_ichimoku_a', 'trend_visual_ichimoku_b', 'trend_aroon_up',\n",
    "       'trend_aroon_down', 'trend_aroon_ind', 'trend_psar_up',\n",
    "       'trend_psar_down', 'trend_psar_up_indicator',\n",
    "       'trend_psar_down_indicator', 'momentum_rsi', 'momentum_tsi',\n",
    "       'momentum_uo', 'momentum_stoch', 'momentum_stoch_signal', 'momentum_wr',\n",
    "       'momentum_ao', 'momentum_kama', 'momentum_roc', 'others_dr',\n",
    "       'others_dlr', 'others_cr']\n",
    "\n",
    "# loading data object\n",
    "data = (DataBunch(df=df,\n",
    "                  pct=0.05,\n",
    "                  window=24,\n",
    "                  lbl_window=12,\n",
    "                  gaxf_type='gadf',\n",
    "                  ta_to_remove=ta_to_remove)\n",
    "       .bunch(bs=16, shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:24.278421Z",
     "iopub.status.busy": "2020-10-07T00:26:24.277456Z",
     "iopub.status.idle": "2020-10-07T00:26:24.286402Z",
     "shell.execute_reply": "2020-10-07T00:26:24.285433Z",
     "shell.execute_reply.started": "2020-10-07T00:26:24.278421Z"
    }
   },
   "outputs": [],
   "source": [
    "class DelayerScheduler(_LRScheduler):\n",
    "    \"\"\"\n",
    "    CREDIT: https://github.com/pabloppp/pytorch-tools\n",
    "    Start with a flat lr schedule until it reaches N epochs then applies a scheduler\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, delay_epochs, after_scheduler):\n",
    "        self.delay_epochs = delay_epochs\n",
    "        self.after_scheduler = after_scheduler\n",
    "        self.finished = False\n",
    "        super().__init__(optimizer)\n",
    "        \n",
    "    def get_lr(self):\n",
    "        if self.last_epoch >= self.delay_epochs:\n",
    "            if not self.finished:\n",
    "                self.after_scheduler.base_lrs = self.base_lrs\n",
    "                self.finished = True\n",
    "            return self.after_scheduler.get_last_lr()\n",
    "        \n",
    "        return self.base_lrs\n",
    "    \n",
    "    def step(self, epoch=None):\n",
    "        if self.finished:\n",
    "            if epoch is None: \n",
    "                self.after_scheduler.step(None)\n",
    "            else:\n",
    "                self.after_scheduler.step(epoch - self.delay_epochs)\n",
    "        else:\n",
    "            return super(DelayerScheduler, self).step(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:24.539724Z",
     "iopub.status.busy": "2020-10-07T00:26:24.539724Z",
     "iopub.status.idle": "2020-10-07T00:26:24.543713Z",
     "shell.execute_reply": "2020-10-07T00:26:24.543713Z",
     "shell.execute_reply.started": "2020-10-07T00:26:24.539724Z"
    }
   },
   "outputs": [],
   "source": [
    "def FlatCosAnnealScheduler(optimizer, delay_epochs, cosine_annealing_epochs):\n",
    "    base_scheduler = CosineAnnealingLR(optimizer, cosine_annealing_epochs)\n",
    "    return DelayerScheduler(optimizer, delay_epochs, base_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:24.763125Z",
     "iopub.status.busy": "2020-10-07T00:26:24.762130Z",
     "iopub.status.idle": "2020-10-07T00:26:24.768113Z",
     "shell.execute_reply": "2020-10-07T00:26:24.767116Z",
     "shell.execute_reply.started": "2020-10-07T00:26:24.763125Z"
    }
   },
   "outputs": [],
   "source": [
    "def delayer(epochs, pct_start=0.8): return int(epochs * pct_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:24.939679Z",
     "iopub.status.busy": "2020-10-07T00:26:24.938658Z",
     "iopub.status.idle": "2020-10-07T00:26:24.960599Z",
     "shell.execute_reply": "2020-10-07T00:26:24.959632Z",
     "shell.execute_reply.started": "2020-10-07T00:26:24.939679Z"
    }
   },
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    \"\"\"\n",
    "    Keeping track of stats when training a model. Evolution will be all training stats for the entire training while summary is epoch summary per epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.evolution = {'train_loss':[], 'train_acc':[], 'valid_loss':[], 'valid_acc':[]}\n",
    "        self.summary = {'train_loss_summary':[], 'train_acc_summary':[], 'valid_loss_summary':[], 'valid_acc_summary':[]}\n",
    "        self.best_stats = {}\n",
    "        \n",
    "    def update_summary(self, train_loss, train_acc, valid_loss, valid_acc):\n",
    "        \"\"\"Call after each epoch\"\"\"\n",
    "        self.summary['train_loss_summary'].append(train_loss)\n",
    "        self.summary['train_acc_summary'].append(train_acc)\n",
    "        self.summary['valid_loss_summary'].append(valid_loss)\n",
    "        self.summary['valid_acc_summary'].append(valid_acc)\n",
    "    \n",
    "    def update_evolution(self, ds_type, loss, acc):\n",
    "        \"\"\"Call after each batch\"\"\"\n",
    "        if ds_type=='train':\n",
    "            self.evolution['train_loss'].append(loss)\n",
    "            self.evolution['train_acc'].append(acc)\n",
    "        elif ds_type=='valid':\n",
    "            self.evolution['valid_loss'].append(loss)\n",
    "            self.evolution['valid_acc'].append(acc)\n",
    "        else: return\n",
    "        \n",
    "    def update_best_stats(self, iteration, train_loss, train_acc, valid_loss, valid_acc):\n",
    "        self.best_stats['iteration'] = iteration\n",
    "        self.best_stats['train_loss'] = train_loss\n",
    "        self.best_stats['train_acc'] = train_acc\n",
    "        self.best_stats['valid_losss'] = valid_loss\n",
    "        self.best_stats['valid_acc'] = valid_acc\n",
    "        \n",
    "    def report(self):\n",
    "        tq.write(f\"\"\"Train loss: {self.summary['train_loss_summary'][-1]:0f}, Train acc: {self.summary['train_acc_summary'][-1]:0f}, Valid loss: {self.summary['valid_loss_summary'][-1]:0f}, Valid acc: {self.summary['valid_acc_summary'][-1]:0f}\"\"\")\n",
    "        \n",
    "    def summarize(self): self.summary = pd.DataFrame(self.summary)\n",
    "    \n",
    "    def report_best(self):\n",
    "        print(f\"\"\"\n",
    "        Best Model Stats:\n",
    "        ---------------------------------\n",
    "        Iteration  : {self.best_stats['iteration']}\n",
    "        Train Loss : {self.best_stats['train_loss']}\n",
    "        Train Acc  : {self.best_stats['train_acc']}\n",
    "        Valid Loss : {self.best_stats['valid_loss']}\n",
    "        Valid Acc  : {self.best_stats['valid_acc']}\n",
    "        \"\"\")\n",
    "        \n",
    "    def plot_summary(self):\n",
    "        if isinstance(self.summary, pd.DataFrame): self.summary.plot()\n",
    "            \n",
    "    def plot_evolution(self):\n",
    "        fig, axs = plt.subplots(2,2, figsize=(15,10))\n",
    "        \n",
    "        axs[0,0].plot(self.evolution['train_acc'])\n",
    "        axs[0,0].set_xlabel('Iterations')\n",
    "        axs[0,0].set_ylabel('Accuracy')\n",
    "        axs[0,0].set_title('Train Accuracy')\n",
    "        \n",
    "        axs[0,1].plot(self.evolution['valid_acc'])\n",
    "        axs[0,1].set_xlabel('Iterations')\n",
    "        axs[0,1].set_ylabel('Accuracy')\n",
    "        axs[0,1].set_title('Valid Accuracy')\n",
    "        \n",
    "        axs[1,0].plot(self.evolution['train_loss'])\n",
    "        axs[1,0].set_xlabel('Iterations')\n",
    "        axs[1,0].set_ylabel('Loss')\n",
    "        axs[1,0].set_title('Train Loss')\n",
    "        \n",
    "        axs[1,1].plot(self.evolution['valid_loss'])\n",
    "        axs[1,1].set_xlabel('Iterations')\n",
    "        axs[1,1].set_ylabel('Loss')\n",
    "        axs[1,1].set_title('Valid Loss')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:25.094240Z",
     "iopub.status.busy": "2020-10-07T00:26:25.093283Z",
     "iopub.status.idle": "2020-10-07T00:26:25.097267Z",
     "shell.execute_reply": "2020-10-07T00:26:25.097267Z",
     "shell.execute_reply.started": "2020-10-07T00:26:25.094240Z"
    }
   },
   "outputs": [],
   "source": [
    "def metrics_batch(output, target, metric_fn=None):\n",
    "    if metric_fn: return metric_fn(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:25.245834Z",
     "iopub.status.busy": "2020-10-07T00:26:25.244839Z",
     "iopub.status.idle": "2020-10-07T00:26:25.250821Z",
     "shell.execute_reply": "2020-10-07T00:26:25.249857Z",
     "shell.execute_reply.started": "2020-10-07T00:26:25.245834Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_batch(loss_fn, output, target, metric_fn=None, opt_fn=None, scheduler=None):\n",
    "    \"\"\"\n",
    "    Calculate loss and metric for batch\n",
    "    \"\"\"\n",
    "    loss = loss_fn(output, target)\n",
    "    metric = metrics_batch(output, target, metric_fn)\n",
    "    \n",
    "    if opt_fn:\n",
    "        opt_fn.zero_grad()\n",
    "        loss.backward()\n",
    "        opt_fn.step()\n",
    "        if scheduler: scheduler.step()\n",
    "            \n",
    "    return loss.data.cpu().item(), metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:25.423360Z",
     "iopub.status.busy": "2020-10-07T00:26:25.422364Z",
     "iopub.status.idle": "2020-10-07T00:26:25.431340Z",
     "shell.execute_reply": "2020-10-07T00:26:25.431340Z",
     "shell.execute_reply.started": "2020-10-07T00:26:25.423360Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_epoch(model, dataloader, ds_type, evaluator, loss_fn, metric_fn=None, opt_fn=None, scheduler=None, device=None, inner_bar=None, inner_loop=None):\n",
    "    \"\"\"\n",
    "    Calculates loss per batch\n",
    "    \"\"\"\n",
    "    running_loss, running_metric = 0,0\n",
    "    n = len(dataloader.dataset)\n",
    "    device = torch.device('cpu') if device is None else device\n",
    "    \n",
    "    for i,(xb,yb) in enumerate(dataloader):\n",
    "        inner_bar.update(1)\n",
    "        nb = yb.size(0)\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "        \n",
    "        loss_b, metric_b = loss_batch(loss_fn, output, yb, metric_fn, opt_fn, scheduler)\n",
    "        running_loss+=loss_b\n",
    "        running_metric+=metric_b\n",
    "        evaluator.update_evolution(ds_type, running_loss/(nb*(i+1)), running_metric/(nb*(i+1)))\n",
    "        \n",
    "    metric_e = running_metric/float(n)\n",
    "    loss_e = running_loss/float(n)\n",
    "    return metric_e, loss_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:25.578945Z",
     "iopub.status.busy": "2020-10-07T00:26:25.577947Z",
     "iopub.status.idle": "2020-10-07T00:26:25.593904Z",
     "shell.execute_reply": "2020-10-07T00:26:25.593904Z",
     "shell.execute_reply.started": "2020-10-07T00:26:25.578945Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(learn, epochs=10, device=None, keep_best_state=True, **kwargs):\n",
    "    \"\"\"\n",
    "    train model with one cycle policy\n",
    "    \"\"\"\n",
    "    evaluator = Evaluate()\n",
    "    \n",
    "    # update opt\n",
    "    opt_fn = learn.opt_fn\n",
    "    \n",
    "    # base\n",
    "    loss_fn = learn.loss_fn\n",
    "    train_dl = learn.data.train_dl\n",
    "    valid_dl = learn.data.valid_dl\n",
    "    metric_fn = learn.metric_fn\n",
    "    device = learn.device if device is None else torch.device(device)\n",
    "    model = learn.model.to(device)\n",
    "    \n",
    "    # display settings\n",
    "    outter_bar = tqdm.tqdm(range(epochs))\n",
    "    outter_loop = range(epochs)\n",
    "    train_n = len(train_dl)\n",
    "    train_inner_bar = tqdm.tqdm(range(train_n), leave=False)\n",
    "    train_inner_loop = range(train_n)\n",
    "    valid_n = len(valid_dl)\n",
    "    valid_inner_bar = tqdm.tqdm(range(valid_n), leave=False)\n",
    "    valid_inner_loop = range(valid_n)\n",
    "    \n",
    "    # best model weights\n",
    "    if keep_best_state:\n",
    "        best_model_wts = deepcopy(model.state_dict())\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "    # Training\n",
    "    for epoch in outter_loop:\n",
    "        train_inner_bar.reset()\n",
    "        valid_inner_bar.reset()\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_metric, train_loss = loss_epoch(model, train_dl, 'train', evaluator, loss_fn, metric_fn, opt_fn, None, device, train_inner_bar, train_inner_loop)\n",
    "        \n",
    "        # eval\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_metric, valid_loss = loss_epoch(model, valid_dl, 'valid', evaluator, loss_fn, metric_fn, device=device, inner_bar=valid_inner_bar, inner_loop=valid_inner_loop)\n",
    "            \n",
    "        # update evaluator\n",
    "        evaluator.update_summary(train_loss, train_metric, valid_loss, valid_metric)\n",
    "        \n",
    "        # keeping best\n",
    "        if keep_best_state:\n",
    "            if valid_loss<best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                evaluator.update_best_stats(epoch+1, train_loss, train_metric, valid_loss, valid_metric)\n",
    "                \n",
    "        # report\n",
    "        outter_bar.update(1)\n",
    "        evaluator.report()\n",
    "        \n",
    "    # summurize training\n",
    "    evaluator.summarize()\n",
    "    learn.evaluator = evaluator\n",
    "    \n",
    "    # keep best weights\n",
    "    if keep_best_state: learn.model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:25.753477Z",
     "iopub.status.busy": "2020-10-07T00:26:25.753477Z",
     "iopub.status.idle": "2020-10-07T00:26:25.768437Z",
     "shell.execute_reply": "2020-10-07T00:26:25.768437Z",
     "shell.execute_reply.started": "2020-10-07T00:26:25.753477Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_one_cycle(learn, epochs=10, pct_start=0.8, div_factor=10., moms=(0.85, 0.95), device=None, keep_best_state=True, **kwargs):\n",
    "    \"\"\"\n",
    "    train model with one cycle policy\n",
    "    \"\"\"\n",
    "    # setting training params\n",
    "    evaluator = Evaluate()\n",
    "    \n",
    "    # scheduler params\n",
    "    steps_per_epoch = len(learn.data.train_dl)\n",
    "    b1, b2 = moms\n",
    "    opt_fn = learn.opt_fn\n",
    "    scheduler = lr_scheduler.OneCycleLR(opt_fn, max_lr=max_lr, steps_per_epoch=steps_per_epoch, epochs=epochs, pct_start=pct_start, div_factor=div_factor, base_momentum=b1, max_momentum=b2)\n",
    "    \n",
    "    # base\n",
    "    loss_fn = learn.loss_fn\n",
    "    train_dl = learn.data.train_dl\n",
    "    valid_dl = learn.data.valid_dl\n",
    "    metric_fn = learn.metric_fn\n",
    "    device = learn.device if device is None else torch.device(device)\n",
    "    model = learn.model.to(device)\n",
    "    \n",
    "    # display settings\n",
    "    outter_bar = tqdm.tqdm(range(epochs))\n",
    "    outter_loop = range(epochs)\n",
    "    train_n = len(train_dl)\n",
    "    train_inner_bar = tqdm.tqdm(range(train_n), leave=False)\n",
    "    train_inner_loop = range(train_n)\n",
    "    valid_n = len(valid_dl)\n",
    "    valid_inner_bar = tqdm.tqdm(range(valid_n), leave=False)\n",
    "    valid_inner_loop = range(valid_n)\n",
    "    \n",
    "    # best model weights\n",
    "    if keep_best_state:\n",
    "        best_model_wts = deepcopy(model.state_dict())\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "    # Training\n",
    "    for epoch in outter_loop:\n",
    "        train_inner_bar.reset()\n",
    "        valid_inner_bar.reset()\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_metric, train_loss = loss_epoch(model, train_dl, 'train', evaluator, loss_fn, metric_fn, opt_fn, scheduler, device, train_inner_bar, train_inner_loop)\n",
    "        \n",
    "        # eval\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_metric, valid_loss = loss_epoch(model, valid_dl, 'valid', evaluator, loss_fn, metric_fn, device=device, inner_bar=valid_inner_bar, inner_loop=valid_inner_loop)\n",
    "            \n",
    "        # update evaluator\n",
    "        evaluator.update_summary(train_loss, train_metric, valid_loss, valid_metric)\n",
    "        \n",
    "        # keeping best\n",
    "        if keep_best_state:\n",
    "            if valid_loss<best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                evaluator.update_best_stats(epoch+1, train_loss, train_metric, valid_loss, valid_metric)\n",
    "                \n",
    "        # report\n",
    "        outter_bar.update(1)\n",
    "        evaluator.report()\n",
    "        \n",
    "    # summurize training\n",
    "    evaluator.summarize()\n",
    "    learn.evaluator = evaluator\n",
    "    \n",
    "    # keep best weights\n",
    "    if keep_best_state: learn.model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:25.936986Z",
     "iopub.status.busy": "2020-10-07T00:26:25.935989Z",
     "iopub.status.idle": "2020-10-07T00:26:25.955936Z",
     "shell.execute_reply": "2020-10-07T00:26:25.954938Z",
     "shell.execute_reply.started": "2020-10-07T00:26:25.936986Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_flat_anneal(learn, epochs=10, pct_start=0.8, div_factor=10., moms=(0.85, 0.95), device=None, keep_best_state=True, **kwargs):\n",
    "    \"\"\"\n",
    "    train model with one cycle policy\n",
    "    \"\"\"\n",
    "    evaluator = Evaluate()\n",
    "    \n",
    "    # scheduler params\n",
    "    steps_per_epoch = len(learn.data.train_dl)\n",
    "    b1, b2 = moms\n",
    "    delay_epochs = delayer(epochs, pct_start)\n",
    "    opt_fn = learn.opt_fn\n",
    "    base_scheduler = CosineAnnealingLR(opt_fn, delay_epochs)\n",
    "    delayed_scheduler = DelayerScheduler(opt_fn, epochs-delay_epochs, base_scheduler)\n",
    "    \n",
    "    # base\n",
    "    loss_fn = learn.loss_fn\n",
    "    train_dl = learn.data.train_dl\n",
    "    valid_dl = learn.data.valid_dl\n",
    "    metric_fn = learn.metric_fn\n",
    "    device = learn.device if device is None else torch.device(device)\n",
    "    model = learn.model.to(device)\n",
    "    \n",
    "    # display settings\n",
    "    outter_bar = tqdm.tqdm(range(epochs))\n",
    "    outter_loop = range(epochs)\n",
    "    train_n = len(train_dl)\n",
    "    train_inner_bar = tqdm.tqdm(range(train_n), leave=False)\n",
    "    train_inner_loop = range(train_n)\n",
    "    valid_n = len(valid_dl)\n",
    "    valid_inner_bar = tqdm.tqdm(range(valid_n), leave=False)\n",
    "    valid_inner_loop = range(valid_n)\n",
    "    \n",
    "    # best model weights\n",
    "    if keep_best_state:\n",
    "        best_model_wts = deepcopy(model.state_dict())\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "    # Training\n",
    "    for epoch in outter_loop:\n",
    "        train_inner_bar.reset()\n",
    "        valid_inner_bar.reset()\n",
    "        \n",
    "        # train\n",
    "        model.train()\n",
    "        train_metric, train_loss = loss_epoch(model, train_dl, 'train', evaluator, loss_fn, metric_fn, opt_fn, None, device, train_inner_bar, train_inner_loop)\n",
    "        \n",
    "        # eval\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_metric, valid_loss = loss_epoch(model, valid_dl, 'valid', evaluator, loss_fn, metric_fn, device=device, inner_bar=valid_inner_bar, inner_loop=valid_inner_loop)\n",
    "            \n",
    "        # update evaluator\n",
    "        evaluator.update_summary(train_loss, train_metric, valid_loss, valid_metric)\n",
    "        \n",
    "        # keeping best\n",
    "        if keep_best_state:\n",
    "            if valid_loss<best_loss:\n",
    "                best_loss = valid_loss\n",
    "                best_model_wts = deepcopy(model.state_dict())\n",
    "                evaluator.update_best_stats(epoch+1, train_loss, train_metric, valid_loss, valid_metric)\n",
    "                \n",
    "        # update scheduler\n",
    "        delayed_scheduler.step()\n",
    "        \n",
    "        # report\n",
    "        outter_bar.update(1)\n",
    "        evaluator.report()\n",
    "        \n",
    "    # summurize training\n",
    "    evaluator.summarize()\n",
    "    learn.evaluator = evaluator\n",
    "    \n",
    "    # keep best weights\n",
    "    if keep_best_state: learn.model.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:26.096560Z",
     "iopub.status.busy": "2020-10-07T00:26:26.096560Z",
     "iopub.status.idle": "2020-10-07T00:26:26.101547Z",
     "shell.execute_reply": "2020-10-07T00:26:26.100549Z",
     "shell.execute_reply.started": "2020-10-07T00:26:26.096560Z"
    }
   },
   "outputs": [],
   "source": [
    "Learner.fit = fit\n",
    "Learner.fit_one_cycle = fit_one_cycle\n",
    "Learner.fit_flat_anneal = fit_flat_anneal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:26.723914Z",
     "iopub.status.busy": "2020-10-07T00:26:26.723914Z",
     "iopub.status.idle": "2020-10-07T00:26:26.739866Z",
     "shell.execute_reply": "2020-10-07T00:26:26.739866Z",
     "shell.execute_reply.started": "2020-10-07T00:26:26.723914Z"
    }
   },
   "outputs": [],
   "source": [
    "from nb.optimizers import Ranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:27.251470Z",
     "iopub.status.busy": "2020-10-07T00:26:27.251470Z",
     "iopub.status.idle": "2020-10-07T00:26:27.372175Z",
     "shell.execute_reply": "2020-10-07T00:26:27.372175Z",
     "shell.execute_reply.started": "2020-10-07T00:26:27.251470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranger optimizer loaded. \n",
      "Gradient Centralization usage = True\n",
      "GC applied to both conv and fc layers\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.98\n",
    "mom = 0.94\n",
    "wd = 0.\n",
    "lr = 1e-4\n",
    "eps = 1e-6\n",
    "\n",
    "in_c, num_classes = model_config(data)\n",
    "model = mininet(in_c, num_classes=num_classes)\n",
    "\n",
    "opt_fn = Ranger(params=model.parameters(), betas=(mom, alpha), eps=eps, weight_decay=wd, lr=lr)\n",
    "\n",
    "learn = Learner(\n",
    "    data,\n",
    "    model,\n",
    "    opt_fn=opt_fn,\n",
    "    lr=lr,\n",
    "    wd=wd\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:26:28.025401Z",
     "iopub.status.busy": "2020-10-07T00:26:28.024403Z",
     "iopub.status.idle": "2020-10-07T00:30:28.836695Z",
     "shell.execute_reply": "2020-10-07T00:30:28.836695Z",
     "shell.execute_reply.started": "2020-10-07T00:26:28.025401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f616ab6ca624701ab13c6ccda46efd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1843.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=96.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.048435, Train acc: 0.500424, Valid loss: 0.045794, Valid acc: 0.510471\n",
      "Train loss: 0.042886, Train acc: 0.560539, Valid loss: 0.047371, Valid acc: 0.481021\n",
      "Train loss: 0.040839, Train acc: 0.617566, Valid loss: 0.047545, Valid acc: 0.480366\n",
      "Train loss: 0.038087, Train acc: 0.667537, Valid loss: 0.050149, Valid acc: 0.494764\n",
      "Train loss: 0.034222, Train acc: 0.724972, Valid loss: 0.053341, Valid acc: 0.492801\n",
      "Train loss: 0.029696, Train acc: 0.775079, Valid loss: 0.056659, Valid acc: 0.503272\n",
      "Train loss: 0.024850, Train acc: 0.822811, Valid loss: 0.065380, Valid acc: 0.500000\n",
      "Train loss: 0.020793, Train acc: 0.856363, Valid loss: 0.069151, Valid acc: 0.503272\n",
      "Train loss: 0.017388, Train acc: 0.883774, Valid loss: 0.075423, Valid acc: 0.489529\n",
      "Train loss: 0.015057, Train acc: 0.900329, Valid loss: 0.087480, Valid acc: 0.486257\n"
     ]
    }
   ],
   "source": [
    "learn.fit(2, keep_best_state=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:36:16.812328Z",
     "iopub.status.busy": "2020-10-07T00:36:16.812328Z",
     "iopub.status.idle": "2020-10-07T00:36:16.816339Z",
     "shell.execute_reply": "2020-10-07T00:36:16.816339Z",
     "shell.execute_reply.started": "2020-10-07T00:36:16.812328Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:36:27.122587Z",
     "iopub.status.busy": "2020-10-07T00:36:27.122587Z",
     "iopub.status.idle": "2020-10-07T00:36:32.783038Z",
     "shell.execute_reply": "2020-10-07T00:36:32.783038Z",
     "shell.execute_reply.started": "2020-10-07T00:36:27.122587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9691963225565695"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = 0\n",
    "for xb,yb in data.train_dl:\n",
    "    xb = xb.to(device)\n",
    "    out = learn.model(xb)\n",
    "    out = torch.argmax(out.data.cpu(),1)\n",
    "    yb = yb.squeeze(1).long()\n",
    "    corr = (out==yb).sum().item()\n",
    "    correct+=corr\n",
    "    \n",
    "correct/len(data.train_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-07T00:36:33.778504Z",
     "iopub.status.busy": "2020-10-07T00:36:33.778504Z",
     "iopub.status.idle": "2020-10-07T00:36:33.788478Z",
     "shell.execute_reply": "2020-10-07T00:36:33.788478Z",
     "shell.execute_reply.started": "2020-10-07T00:36:33.778504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss_summary</th>\n",
       "      <th>train_acc_summary</th>\n",
       "      <th>valid_loss_summary</th>\n",
       "      <th>valid_acc_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.048435</td>\n",
       "      <td>0.500424</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>0.510471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.042886</td>\n",
       "      <td>0.560539</td>\n",
       "      <td>0.047371</td>\n",
       "      <td>0.481021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040839</td>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.047545</td>\n",
       "      <td>0.480366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038087</td>\n",
       "      <td>0.667537</td>\n",
       "      <td>0.050149</td>\n",
       "      <td>0.494764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034222</td>\n",
       "      <td>0.724972</td>\n",
       "      <td>0.053341</td>\n",
       "      <td>0.492801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.029696</td>\n",
       "      <td>0.775079</td>\n",
       "      <td>0.056659</td>\n",
       "      <td>0.503272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.024850</td>\n",
       "      <td>0.822811</td>\n",
       "      <td>0.065380</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.020793</td>\n",
       "      <td>0.856363</td>\n",
       "      <td>0.069151</td>\n",
       "      <td>0.503272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.017388</td>\n",
       "      <td>0.883774</td>\n",
       "      <td>0.075423</td>\n",
       "      <td>0.489529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015057</td>\n",
       "      <td>0.900329</td>\n",
       "      <td>0.087480</td>\n",
       "      <td>0.486257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss_summary  train_acc_summary  valid_loss_summary  \\\n",
       "0            0.048435           0.500424            0.045794   \n",
       "1            0.042886           0.560539            0.047371   \n",
       "2            0.040839           0.617566            0.047545   \n",
       "3            0.038087           0.667537            0.050149   \n",
       "4            0.034222           0.724972            0.053341   \n",
       "5            0.029696           0.775079            0.056659   \n",
       "6            0.024850           0.822811            0.065380   \n",
       "7            0.020793           0.856363            0.069151   \n",
       "8            0.017388           0.883774            0.075423   \n",
       "9            0.015057           0.900329            0.087480   \n",
       "\n",
       "   valid_acc_summary  \n",
       "0           0.510471  \n",
       "1           0.481021  \n",
       "2           0.480366  \n",
       "3           0.494764  \n",
       "4           0.492801  \n",
       "5           0.503272  \n",
       "6           0.500000  \n",
       "7           0.503272  \n",
       "8           0.489529  \n",
       "9           0.486257  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.evaluator.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "0. What causes overfitting? Read into this first. Can a simplier model work?\n",
    "1. Play with Thresholds -> look more into the labeling scheme. What happens when we change the thresholds? What are the counts for both the training_dl and valid_dl? Try different extremes and see if there is a difference\n",
    "2. Play with another labeling scheme. Try stationary close again, does this perform differently? \n",
    "3. Attempt more data once more \n",
    "4. Build capsule network -> does this perform different?\n",
    "5. Include an RNN as the decoder -> head -> classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
